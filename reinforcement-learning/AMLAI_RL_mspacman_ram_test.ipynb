{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iLykei Lecture Series\n",
    "\n",
    "# Advanced Machine Learning and Artificial Intelligence (MScA 32017)\n",
    "\n",
    "# Pac-Man Competition for Human-Machine Teams \n",
    "\n",
    "### Y.Balasanov, M. Tselishchev, &copy; iLykei 2018\n",
    "\n",
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load trained model (which was previously saved by `model.save()`-method) for online network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dqn_model(input_shape, nb_actions, dense_layers, dense_units):\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=input_shape))\n",
    "    for i in range(dense_layers):\n",
    "        model.add(Dense(units=dense_units, activation='relu'))\n",
    "        #model.add(BatchNormalization())                                                                                                                                     \n",
    "        #model.add(Dropout(0.5))                                                                                                                                             \n",
    "    model.add(Dense(nb_actions, activation='linear'))\n",
    "    return model\n",
    "\n",
    "input_shape = (128,)\n",
    "nb_actions = 9                                                                                                                                         \n",
    "dense_layers = 7\n",
    "dense_units = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "from keras.models import Sequential, clone_model\n",
    "from keras.layers import Dense, Flatten, Conv2D, InputLayer, Dropout, BatchNormalization\n",
    "from keras.callbacks import CSVLogger, TensorBoard\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "\n",
    "online_network = create_dqn_model(input_shape, nb_actions, dense_layers, dense_units) #load_model('ram_model_4kk.h5f', compile=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "weights_folder = './Competition/MsPacman_DQN_9/weights'\n",
    "online_network.load_weights(os.path.join(weights_folder, 'weights_last.h5f'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define $\\varepsilon$-greedy strategy (using small $\\varepsilon$):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy(q_values, epsilon, n_outputs):\n",
    "    if random.random() < epsilon:\n",
    "        return random.randrange(n_outputs)  # random action\n",
    "    else:\n",
    "        return np.argmax(q_values)          # q-optimal action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing model\n",
    "\n",
    "Define a function to evalutate the trained network. \n",
    "Note that we still using $\\varepsilon$-greedy strategy here to prevent an agent from getting stuck. \n",
    "`test_dqn` returns a list with scores for specific number of games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dqn(n_games, model, nb_actions=9, skip_start=90, eps=0.05, render=False, sleep_time=0.01):\n",
    "    env = gym.make(\"MsPacman-ram-v0\")\n",
    "    scores = []\n",
    "    for i in range(n_games):\n",
    "        obs = env.reset()\n",
    "        score = 0\n",
    "        done = False\n",
    "        for skip in range(skip_start):  # skip the start of each game (it's just freezing time before game starts)\n",
    "            obs, reward, done, info = env.step(0)\n",
    "            score += reward\n",
    "        while not done:\n",
    "            state = obs\n",
    "            q_values = model.predict(np.array([state]))[0]\n",
    "            action = epsilon_greedy(q_values, eps, nb_actions)\n",
    "            obs, reward, done, info = env.step(action)\n",
    "            score += reward\n",
    "            if render:\n",
    "                env.render()\n",
    "                time.sleep(sleep_time)\n",
    "                if done:\n",
    "                    time.sleep(1)\n",
    "        scores.append(score)\n",
    "        print('{}/{}: {}'.format(i+1, n_games, score))\n",
    "        env.close()\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting scores\n",
    "\n",
    "Run 100 games without rendering and collect necessary statistics for final score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/100: 2110.0\n",
      "2/100: 3050.0\n",
      "3/100: 940.0\n",
      "4/100: 920.0\n",
      "5/100: 1560.0\n",
      "6/100: 1820.0\n",
      "7/100: 3500.0\n",
      "8/100: 1440.0\n",
      "9/100: 790.0\n",
      "10/100: 1390.0\n",
      "11/100: 1340.0\n",
      "12/100: 1330.0\n",
      "13/100: 4420.0\n",
      "14/100: 1380.0\n",
      "15/100: 1310.0\n",
      "16/100: 1770.0\n",
      "17/100: 2600.0\n",
      "18/100: 1700.0\n",
      "19/100: 2360.0\n",
      "20/100: 2510.0\n",
      "21/100: 2670.0\n",
      "22/100: 1430.0\n",
      "23/100: 1120.0\n",
      "24/100: 2040.0\n",
      "25/100: 1030.0\n",
      "26/100: 1140.0\n",
      "27/100: 2880.0\n",
      "28/100: 2010.0\n",
      "29/100: 2120.0\n",
      "30/100: 2240.0\n",
      "31/100: 1940.0\n",
      "32/100: 2380.0\n",
      "33/100: 2660.0\n",
      "34/100: 1510.0\n",
      "35/100: 3810.0\n",
      "36/100: 2720.0\n",
      "37/100: 1440.0\n",
      "38/100: 2050.0\n",
      "39/100: 1700.0\n",
      "40/100: 4190.0\n",
      "41/100: 1680.0\n",
      "42/100: 2520.0\n",
      "43/100: 1480.0\n",
      "44/100: 3050.0\n",
      "45/100: 1160.0\n",
      "46/100: 4320.0\n",
      "47/100: 1670.0\n",
      "48/100: 3370.0\n",
      "49/100: 2350.0\n",
      "50/100: 1160.0\n",
      "51/100: 3050.0\n",
      "52/100: 2210.0\n",
      "53/100: 1940.0\n",
      "54/100: 1140.0\n",
      "55/100: 5490.0\n",
      "56/100: 1850.0\n",
      "57/100: 2190.0\n",
      "58/100: 1840.0\n",
      "59/100: 4670.0\n",
      "60/100: 2570.0\n",
      "61/100: 2560.0\n",
      "62/100: 1260.0\n",
      "63/100: 2720.0\n",
      "64/100: 3730.0\n",
      "65/100: 5660.0\n",
      "66/100: 2020.0\n",
      "67/100: 1860.0\n",
      "68/100: 1920.0\n",
      "69/100: 2530.0\n",
      "70/100: 3440.0\n",
      "71/100: 1730.0\n",
      "72/100: 2490.0\n",
      "73/100: 2110.0\n",
      "74/100: 2740.0\n",
      "75/100: 1110.0\n",
      "76/100: 1880.0\n",
      "77/100: 1270.0\n",
      "78/100: 1500.0\n",
      "79/100: 1860.0\n",
      "80/100: 1560.0\n",
      "81/100: 800.0\n",
      "82/100: 1550.0\n",
      "83/100: 1790.0\n",
      "84/100: 1550.0\n",
      "85/100: 4530.0\n",
      "86/100: 590.0\n",
      "87/100: 3990.0\n",
      "88/100: 680.0\n",
      "89/100: 1740.0\n",
      "90/100: 4170.0\n",
      "91/100: 1320.0\n",
      "92/100: 2510.0\n",
      "93/100: 1770.0\n",
      "94/100: 1750.0\n",
      "95/100: 2300.0\n",
      "96/100: 2900.0\n",
      "97/100: 1760.0\n",
      "98/100: 1580.0\n",
      "99/100: 2480.0\n",
      "100/100: 3780.0\n",
      "\n",
      "Fifth percentile:  4325.0\n"
     ]
    }
   ],
   "source": [
    "ngames = 100\n",
    "eps = 0.01\n",
    "render = False\n",
    "\n",
    "scores = test_dqn(ngames, online_network, eps=eps, render=render)\n",
    "\n",
    "#print('\\nMean score: ', np.mean(scores))\n",
    "#print('\\nMax score: ', np.max(scores))\n",
    "#print('\\nPercentiles:')\n",
    "#print([ np.percentile(scores, p) for p in [0, 25, 50, 75, 100] ])\n",
    "print('\\nFifth percentile: ',np.percentile(scores,95))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rendering\n",
    "\n",
    "Play 3 more times with rendering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5: 2660.0\n",
      "2/5: 1530.0\n",
      "3/5: 3060.0\n",
      "4/5: 2580.0\n",
      "5/5: 1740.0\n",
      "\n",
      "Mean score:  2314.0\n",
      "\n",
      "Max score:  3060.0\n",
      "\n",
      "Percentiles:\n",
      "[1530.0, 1740.0, 2580.0, 2660.0, 3060.0]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "ngames = 5\n",
    "eps = 0.05\n",
    "render = True\n",
    "\n",
    "scores = test_dqn(ngames, online_network, eps=eps, render=render)\n",
    "\n",
    "print('\\nMean score: ', np.mean(scores))\n",
    "print('\\nMax score: ', np.max(scores))\n",
    "print('\\nPercentiles:')\n",
    "print([ np.percentile(scores, p) for p in [0, 25, 50, 75, 100] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
