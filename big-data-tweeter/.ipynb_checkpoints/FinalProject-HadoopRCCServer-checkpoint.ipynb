{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0.cloudera1\n"
     ]
    }
   ],
   "source": [
    "#Ensure we are using the right kernel\n",
    "print (sc.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sh\n",
    "import shutil\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs_working_data_dir = \"/user/ivy2/Tweets\"\n",
    "hdfs_output_dir = \"/user/adeshghadge/FinalProject/output\"\n",
    "linux_output_directory = \"/home/adeshghadge/FinalProject/output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#tweeter_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filter_keywords = \\\n",
    "[\"uchicago\", \"university of chicago\", \"uofc\", \"maroonmade\", \"maroon made\", \"chicago maroon\", \\\n",
    " \"chicago booth\", \"booth school of business\", \"graham school of continuing liberal and professional studies\" \\\n",
    "\"kellogg school of management\", \"northwestern university\", \"willie the wildcat\", \"northwestern wildcat\", \\\n",
    " \"harvard\", \"harvard crimson\", \"university of michigan\", \"umich\", \"michigan wolverines\", \"ross school of business\",\\\n",
    " \"princeton university\", \"princetonu\", \"princeton tigers\"]\n",
    "\n",
    "#filter_keywords = \\\n",
    "#[\"princeton university\", \"princetonu\", \"princeton tigers\"]\n",
    "\n",
    "filter_keywords_uchicago = \\\n",
    "[\"uchicago\", \"university of chicago\", \"uofc\",\\\n",
    " \"maroonmade\", \"maroon made\", \"chicago maroon\", \n",
    " \"chicago booth\", \"booth school of business\", \\\n",
    "\"graham school of continuing liberal and professional studies\"]\n",
    "\n",
    "filter_keywords_northwestern = \\\n",
    "[\"kellogg school of management\", \"northwestern university\", \"willie the wildcat\", \"northwestern wildcat\"]\n",
    "\n",
    "filter_keywords_harvard = \\\n",
    "[\"harvard\", \"harvard crimson\"]\n",
    "\n",
    "filter_keywords_umichigan = \\\n",
    "[\"university of michigan\", \"umich\", \"michigan wolverines\", \\\n",
    "\"ross school of business\"]\n",
    "\n",
    "filter_keywords_princeton = \\\n",
    "[\"princeton university\", \"princetonu\", \"princeton tigers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findString(tweet, retweet, extended_tweet):\n",
    "    for filterWord in filter_keywords:\n",
    "        if((tweet is not None and tweet.lower().find(filterWord) >= 0) or \\\n",
    "           (retweet is not None and retweet.lower().find(filterWord) >= 0) or \\\n",
    "           (extended_tweet is not None and extended_tweet.lower().find(filterWord) >= 0)):\n",
    "            return True\n",
    "            \n",
    "    return False;    \n",
    "\n",
    "findUdf = udf(findString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyTweet(tweet, retweet, extended_tweet):\n",
    "    for filterWord in filter_keywords_uchicago:\n",
    "        if((tweet is not None and tweet.lower().find(filterWord) >= 0) or \\\n",
    "           (retweet is not None and retweet.lower().find(filterWord) >= 0) or \\\n",
    "           (extended_tweet is not None and extended_tweet.lower().find(filterWord) >= 0)):\n",
    "            return \"uchicago\"\n",
    "        \n",
    "    for filterWord in filter_keywords_northwestern:\n",
    "        if((tweet is not None and tweet.lower().find(filterWord) >= 0) or \\\n",
    "           (retweet is not None and retweet.lower().find(filterWord) >= 0) or \\\n",
    "           (extended_tweet is not None and extended_tweet.lower().find(filterWord) >= 0)):\n",
    "            return \"northwestern\"  \n",
    "        \n",
    "    for filterWord in filter_keywords_harvard:\n",
    "        if((tweet is not None and tweet.lower().find(filterWord) >= 0) or \\\n",
    "           (retweet is not None and retweet.lower().find(filterWord) >= 0) or \\\n",
    "           (extended_tweet is not None and extended_tweet.lower().find(filterWord) >= 0)):\n",
    "            return \"harvard\"        \n",
    "\n",
    "    for filterWord in filter_keywords_umichigan:\n",
    "        if((tweet is not None and tweet.lower().find(filterWord) >= 0) or \\\n",
    "           (retweet is not None and retweet.lower().find(filterWord) >= 0) or \\\n",
    "           (extended_tweet is not None and extended_tweet.lower().find(filterWord) >= 0)):\n",
    "            return \"umichigan\"\n",
    "\n",
    "    for filterWord in filter_keywords_princeton:\n",
    "        if((tweet is not None and tweet.lower().find(filterWord) >= 0) or \\\n",
    "           (retweet is not None and retweet.lower().find(filterWord) >= 0) or \\\n",
    "           (extended_tweet is not None and extended_tweet.lower().find(filterWord) >= 0)):\n",
    "            return \"princeton\"        \n",
    "        \n",
    "    return \"none\";    \n",
    "\n",
    "classifyUdf = udf(classifyTweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweeter_data = spark.read.json('hdfs:///' + hdfs_working_data_dir + '/*.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_filtered = tweeter_data\\\n",
    "                    .filter(\"id is not null and ltrim(rtrim(id)) <> '' and ((text is not null and ltrim(rtrim(text)) <> '') \\\n",
    "                    or (retweeted_status.text is not null and ltrim(rtrim(retweeted_status.text)) <> '') \\\n",
    "                    or (extended_tweet.full_text is not null and ltrim(rtrim(extended_tweet.full_text)) <> ''))\")\\\n",
    "                    .withColumn(\"relevantTweet\", findUdf(col(\"text\"),\\\n",
    "                                                         col(\"retweeted_status.text\"),\\\n",
    "                                                         col(\"extended_tweet.full_text\")))\\\n",
    "                    .withColumn(\"classifiedTweet\", classifyUdf(col(\"text\"),\\\n",
    "                                                         col(\"retweeted_status.text\"),\\\n",
    "                                                         col(\"extended_tweet.full_text\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_filtered_step2 = tweets_filtered.filter(\"relevantTweet == True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "244607"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_filtered_step2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_filtered_step2.write.format('json').save(hdfs_output_dir+\"/tweets_json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sh.hdfs('dfs', '-getmerge', hdfs_output_dir+\"/tweets_json\", linux_output_directory+\"/tweets.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweeter_data_relevant = spark.read.json('hdfs:///' + hdfs_output_dir + '/tweets_json/*.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_filtered_topusers_uchicago = tweets_filtered\\\n",
    ".filter(\"classifiedTweet == 'uchicago' and relevantTweet == False\")\\\n",
    ".where(col(\"user.id\").isin([31144285, 20270494,417357386,2533835623,790683208111181825]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_filtered_topusers_uchicago.select('user.id', 'user.screen_name', 'text').limit(100).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_filtered_topusers_uchicago.write.format('json').save(hdfs_output_dir+\"/tweets_topusers_uchicago_json2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_filtered_topusers_northwestern = tweets_filtered\\\n",
    ".filter(\"classifiedTweet == 'northwestern' and relevantTweet == False\")\\\n",
    ".where(col(\"user.id\").isin([316331833, 777732985781121025, 3441832812, 3534460642, 783825991487655940]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_filtered_topusers_northwestern.write.format('json').save(hdfs_output_dir+\"/tweets_topusers_northwestern_json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_filtered_topusers_umichigan = tweets_filtered\\\n",
    ".filter(\"classifiedTweet == 'umichigan' and relevantTweet == False\")\\\n",
    ".where(col(\"user.id\").isin([10084232,3441832812,1504446650,3194119656,  26005689,824397861383139328]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_filtered_topusers_umichigan.write.format('json').save(hdfs_output_dir+\"/tweets_topusers_umichigan_json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_filtered_topusers_harvard = tweets_filtered\\\n",
    ".filter(\"classifiedTweet == 'harvard' and relevantTweet == False\")\\\n",
    ".where(col(\"user.id\").isin([880005795974217728, 2376944491,  859728522, 282951115, 279314135]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_filtered_topusers_harvard.write.format('json').save(hdfs_output_dir+\"/tweets_topusers_harvard_json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_filtered_topusers_princeton = tweets_filtered\\\n",
    ".filter(\"classifiedTweet == 'princeton' and relevantTweet == False\")\\\n",
    ".where(col(\"user.id\").isin([998094685, 2879161308, 2507969982, 2507997720, 1870650955]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_filtered_topusers_princeton.write.format('json').save(hdfs_output_dir+\"/tweets_topusers_princeton_json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pySpark 2.2.0 4G",
   "language": "python",
   "name": "pyspark2_4g"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
