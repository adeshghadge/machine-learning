---
title: "Machine Learning - Project Part I"
author: "Adesh Ghadge"
date: "8/18/2018"
output: html_document
---


<style type="text/css"> 

body{ /* Normal  */ 
      font-size: 12px; 
  } 
td {  /* Table  */ 
  font-size: 8px; 
} 

code.r{ /* Code block */ 
    font-size: 12px; 
} 
pre { /* Code block - determines code spacing between lines */ 
    font-size: 14px; 
} 

#header-answer {
  color: blue
}

#answer-text {
   font-size: 12pt;
}

</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Part 1: Regression

```{r, echo=FALSE}
dataPath <- '/Users/adeshghadge/Box Sync/MScA/Courses/Machine Learning & Predictive Analytics/Project/'
```
```{r}
dat<-read.csv(file=paste(dataPath,"slice_localization_data.csv",sep="/"))
```

### Data Exploration
```{r}

#Remove id and target variable
pred<-dat[,c(-1,-386)]

#Set target variable
Y<-dat[,386]

head(colnames(pred))
tail(colnames(pred))
```

```{r}
plot(Y)
```

####{#answer-text}
**We see that Y has high variance.**


```{r}
summary(Y)

hist(Y)
```

####{#answer-text}
**Histogram shows us fat tails and somewhat of a bell-curve in the middle.**


```{r}
qqnorm(Y)
qqline(Y)
```

####{#answer-text}
**The QQ plot diverges quite a bit at the tails. This data will probably fail normality test.**
####{#answer-text}
**Let us perform KS Test to check for normality**
```{r}
ks.test(unique(Y), "pnorm", mean(Y), sd(Y))
```

####{#answer-text}
**The p-value is less 0.05 hence the data fails the test. It is not normally distributed.**


### Linear Regression
```{r}
#Remove id column
data.model <- dat[, -1]

lin.model <- lm(reference ~ ., data = data.model)
lin.model.sm <- summary(lin.model)
```

####{#answer-text}
**Number of significant predictors**
```{r}
length(lin.model.sm$coefficients[,4] <= 0.05)
```

####{#answer-text}
**Remove predictors insignificant with 5% level and predictors returning NA as coefficients. Fit reduced linear model.**
```{r}
lin.model.cols <- rbind(cbind(rownames(lin.model.sm$coefficients[which(lin.model.sm$coefficients[,4] <= 0.05), ][-1,])), "reference")

data.model.2 <- data.model[, lin.model.cols]

lin.model.2 <- lm(reference ~ ., data = data.model.2)
lin.model.sm.2 <- summary(lin.model.2)

vect.lm.chars <- c(AIC = AIC(lin.model.2), R.Sq = lin.model.sm.2$r.squared, MSE = mean(lin.model.sm.2$residuals^2), num.pred = ncol(data.model.2) - 1)

mapply(format, vect.lm.chars)
```


### PCA
```{r, echo=FALSE}
suppressWarnings(library(relaimpo))
suppressWarnings(library(Rfast))
```
```{r}
PCA.model <- prcomp(data.model[,2:ncol(data.model)])

factorLoadings<-PCA.model$rotation
factorScores<- as.matrix(data.model[,2:ncol(data.model)])%*%PCA.model$rotation
zeroLoading<-PCA.model$center
```

####{#answer-text}
**Some of the factor scores have very low variance and will cause calc.relimp to fail. So we remove factor scores columns with variance less than 1e-6**
```{r}
eps <- 1e-6
cols.to.use <- which(colVars(factorScores) > eps)

factorsData<-data.frame(Y=data.model[,1], factorScores[, cols.to.use])
dim(factorsData)

model.PCA <- lm(Y~., data=factorsData)
model.PCA.sm <- summary(model.PCA)

vect.chars.pca <- c(AIC = AIC(model.PCA), R.Sq = model.PCA.sm$r.squared, MSE = mean(model.PCA.sm$residuals^2), num.pred = ncol(factorScores))

mapply(format, vect.chars.pca)
```

####{#answer-text}
**Calculate relative importance of predictors.**
```{r}
metrics.PCA <- calc.relimp(model.PCA, type = c("first"))

sum(metrics.PCA@first)
metrics.PCA.rank <- (metrics.PCA@first.rank)
```

####{#answer-text}
**Reorder predictors based on importance and rerun PCA analysis**
```{r}
orderedFactors<- data.frame(Y=data.model$reference, factorScores[,order(metrics.PCA.rank)])
dim(orderedFactors)

model.orderd.PCA <- lm(Y~.,data=orderedFactors)
model.orderd.PCA.sm <- summary(model.orderd.PCA)
```

####{#answer-text}
**Finally, we look at all characteristics of the fit using the ordered PCA data.**
```{r}
vect.chars.ordered.pca <- c(AIC = AIC(model.orderd.PCA), R.Sq = model.orderd.PCA.sm$r.squared, MSE = mean(model.orderd.PCA.sm$residuals^2), num.pred = ncol(orderedFactors) - 1)

mapply(format, vect.chars.ordered.pca)
```


### Lasso Regression
```{r, echo=FALSE}
suppressWarnings(library(glmnet))
```
```{r}
data.model.mx <- as.matrix(data.model)

model.lasso = glmnet(x=data.model.mx[,1:ncol(data.model.mx)-1],y=data.model.mx[,ncol(data.model.mx)],alpha=1,nlambda=100,lambda.min.ratio=.0001)
plot(model.lasso)

model.cv.lasso <- cv.glmnet(x=data.model.mx[,1:ncol(data.model.mx)-1],y=data.model.mx[,ncol(data.model.mx)], alpha = 1)
plot(model.cv.lasso)

(best.lamda = model.cv.lasso$lambda.min)

model.improved.lasso <- glmnet(x=data.model.mx[,1:ncol(data.model.mx)-1],y=data.model.mx[,ncol(data.model.mx)], lambda = best.lamda, alpha = 1, standardize = F)

lasso.pred=predict(model.improved.lasso,s=best.lamda,
                   newx=data.model.mx[,1:ncol(data.model.mx)-1])

lasso.betas.cols <- names(model.improved.lasso$beta[(which(!(model.improved.lasso$beta == 0))),])

vect.lasso.chars <- c("DevRatio (RSq)" = model.improved.lasso$dev.ratio, MSE = mean((lasso.pred - data.model.mx[,ncol(data.model.mx)])^2), num.pred = length(lasso.betas.cols))
mapply(format, vect.lasso.chars)
```

####{#answer-text}
**Since we cannot calculate AIC from lasso model one way to get it is by removing the predictors corresponding to the coefficients which lasso removed and run a linear model with only the remaining predictors.**
```{r}
lin.model.lasso <- lm(reference ~ ., data = data.model[,c("reference", lasso.betas.cols)])
lasso.model.sm <- summary(lin.model.lasso)

lin.model.cols.lasso <- rbind(cbind(rownames(lasso.model.sm$coefficients[which(lasso.model.sm$coefficients[,4] <= 0.05), ][-1,])), "reference")

data.model.lasso <- data.model[, lin.model.cols.lasso]

lin.model.lasso.2 <- lm(reference ~ ., data = data.model.lasso)
lasso.model.sm.2 <- summary(lin.model.lasso.2)

vect.lasso.chars.2 <- c(AIC = AIC(lin.model.lasso.2), R.Sq = lasso.model.sm.2$r.squared, MSE = mean(lasso.model.sm.2$residuals^2), num.pred = ncol(data.model.lasso) - 1)

mapply(format, vect.lasso.chars.2)
```

### Regression Tree
```{r, echo=FALSE}
suppressWarnings(library(rpart))
suppressWarnings(library(rpart.plot))
suppressWarnings(library(caret))
```

####{#answer-text}
**We fit regression tree from caret package with 10 fold cross validation.**
```{r}
ctrl <- trainControl(method = "cv", number = 10)

treeTrain <- train(reference~., method="rpart", data=data.model, tuneLength = 20, trControl = ctrl)
treeTrain$results

treeTrain$bestTune
treeTrain$finalModel

prp(treeTrain$finalModel,extra=101, # display the number of observations that fall in the node
    branch=.5, # change angle of branch lines
    shadow.col="gray", # shadows under the leaves
    branch.lty=3, # draw branches using dotted lines
    split.cex=1.2, # make the split text larger than the node text
    split.prefix="is ", # put "is " before split text
    split.suffix="?", # put "?" after split text
    split.box.col="lightgray", # lightgray split boxes (default is white)
    split.border.col="darkgray", # darkgray border on split boxes
    split.round=.5,
    nn=TRUE) # display the node numbers, default is FALSE


(treeTrain.MSE<-sum(residuals(treeTrain$finalModel)^2))

vect.caret.tree.chars <- c(R.Sq = treeTrain$results[which(treeTrain$results$cp == treeTrain$bestTune),]$Rsquared, MSE = sum(residuals(treeTrain$finalModel)^2), num.pred = length(predictors(treeTrain)))

mapply(format, vect.caret.tree.chars)
```

### Compare All Models

####{#answer-text}
**Let's compare the characteristics of fit of all the models.**
```{r}
#Linear Model
mapply(format, vect.lm.chars)

#PCA Model
mapply(format, vect.chars.ordered.pca)

#Lasso Model
mapply(format, vect.lasso.chars)

#Regression Tree Model
mapply(format, vect.caret.tree.chars)
```

####{#answer-text}
**Based on the above numbers we can see that the PCA model gives use the best results with R squared value of 0.8644, MSE of 67.699, and AIC of 378082.9**